---
title: "p8105_hw6_yc4018"
author: "Yuxuan Chen"
date: "12/3/2021"
output: github_document
---
```{r message = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis" 
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

### **Problem 1**

1. Load and clean the data for regression analysis 

```{r warning = FALSE}
birthweight_df = 
  read.csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))
knitr::kable(birthweight_df[0:10,])

# check for missing data
sum(is.na(birthweight_df))
```

 - The dimension of this `birthweight_df` dataset is (`r dim(birthweight_df)`). Through data cleaning, I changed the `babysex`, `frace`, `malform`, and `mrace` these categorical variables from numeric to factor. Also, after checking for missing data, there are no missing values in this dataset.   

2. Propose a regression model for birthweight

  - After searching online, I found out that the premature birth, mother's race, age, and health, multiple birth, and whether or not she smokes are the majority causes of low birthweight. Hence, I choose gestational age in weeks (`gaweeks`), mother’s race (`mrace`), mother’s age at delivery (`momage`), mother’s pre-pregnancy BMI (`ppbmi`), number of live births prior to this pregnancy (`parity`), and average number of cigarettes smoked per day during pregnancy(`smoken`) as predictors to predict child's birthweight.
  
```{r}
model_fit1 = lm(bwt ~ gaweeks + mrace + momage + ppbmi + parity + smoken, data = birthweight_df)
broom::tidy(model_fit1)
```

3. plot of model residuals against fitted values

```{r message = FALSE}
birthweight_df %>% 
  modelr::add_predictions(model_fit1) %>% 
  modelr::add_residuals(model_fit1) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(
    title = "Plot of Model1: Residuals Against Fitted Values",
    x = "Fitted values",
    y = "Residuals")

```

4. Fit two other models: 

 - One using length at birth and gestational age as predictors (main effects only)
```{r}
model_fit2 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
```

 - One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
model_fit3 = lm(bwt ~ bhead + blength + babysex + bhead * blength + 
                  bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthweight_df)
```

5. Compute rmse: cross validation.

```{r warning = FALSE}
cv_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    model_fit1 = map(.x = train, ~lm(bwt ~ gaweeks + mrace + momage + ppbmi + parity + smoken, data = .x)),
    model_fit2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_fit3 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + 
                                       bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_model_1 = map2_dbl(.x = model_fit1, .y = test, ~rmse(model = .x, data = .y)), 
    rmse_model_2 = map2_dbl(.x = model_fit2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model_3 = map2_dbl(.x = model_fit3, .y = test, ~rmse(model = .x, data = .y)))
```

6. violin plot of RMSEs 

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
     title = "Violin Plot of RMSEs for Three Models",
     x = "Model",
     y = "RMSE")
  
```

 - Based on the above violin plot of RMSEs for three models, since the model 3 has the smallest RMSE value, it is the best model; and the model 1 which with the largest RMSE value is the worst model. Hence, model 3, the model that has highest prediction accuracy, is the one to use `head circumference`, `length`, `sex`, and all interactions as predictors to predict child’s birthweight. 

### **Problem 2**

```{r message = FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r warning = FALSE}
weather_boot_results = 
  weather_df %>%
    bootstrap(5000, id = "strap_number") %>% 
    mutate(
      models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
      results_r = map(models, broom::glance),
      results_log = map(models, broom::tidy)
    ) %>% 
    select(strap_number, results_r, results_log) %>% 
    unnest(results_r, results_log) %>% 
  select(strap_number, adj.r.squared, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    log_beta1beta2 = log(intercept * tmin)
  ) %>% 
  select(strap_number, adj_r_squared, log_beta1beta2)

```

1. Plot the distribution of $\hat{r}^2$

```{r}
weather_boot_results %>% 
  ggplot(aes(x = adj_r_squared)) +
  geom_density() + 
  labs(
    title = c("Distribution of Adjusted R Squared"),
    x = c("Adjusted R Squared"),
    y = c("Density")
  )

```

 - Based on the above plot we can see that, the distribution of $\hat{r}^2$ is nearly normally distributed around the mean of roughly 0.912. 

2. Plot the distribution of $log(\widehat{\beta}_0 * \widehat{\beta}_1)$: 

```{r}
weather_boot_results %>% 
  ggplot(aes(x = log_beta1beta2)) +
  geom_density() + 
  labs(
    title = c("Distribution of log(beta1*beta2)"),
    x = c("log(beta1*beta2)"),
    y = c("Density")
  )
```

 - Based on the above plot we can see that, the distribution of $log(\widehat{\beta}_0 * \widehat{\beta}_1)$ is nearly normally distributed around the mean of roughly 2.02. 

3. 95% confidence interval for $\hat{r}^2$ and $log(\widehat{\beta}_0 * \widehat{\beta}_1)$:

```{r}
weather_boot_results %>% 
  summarize(
    ci_lower_r = quantile(adj_r_squared, 0.025),
    ci_upper_r = quantile(adj_r_squared, 0.975),
    ci_lower_log = quantile(log_beta1beta2, 0.025),
    ci_upper_log = quantile(log_beta1beta2, 0.975),
  )
```

 - Hence, the 95% confidence interval for $\hat{r}^2$ is (0.893, 0.927). We are 95% confident that the $\hat{r}^2$ is between 0.893 and 0.927.     
   And the 95% confidence interval for $log(\widehat{\beta}_0 * \widehat{\beta}_1)$ is (1.966, 2.059). We are 95% confident that the $log(\widehat{\beta}_0 * \widehat{\beta}_1)$ is between 1.966 and 2.059.     
 
 
 